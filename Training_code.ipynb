{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN_Polar_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "%matplotlib inline\n",
    "import gc\n",
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_power: 0.7962143411069945\n",
      "noise_sigma: 0.6309573444801932\n"
     ]
    }
   ],
   "source": [
    "k = 11\n",
    "N = 64\n",
    "R = k/N\n",
    "SNR_dB = 4      \n",
    "noise_power = 1/10**(SNR_dB/10)\n",
    "noise_power = noise_power * 2\n",
    "print(\"noise_power:\", noise_power)    # 1/2*No\n",
    "print(\"noise_sigma:\", np.sqrt(noise_power/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Noise & Modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPSK_modulator(x):\n",
    "    return -2*x +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qpsk_NRZ_encoder(x):\n",
    "    half_CWs = int(x.shape[1]/2)    # half codewords length\n",
    "    for i in range(x.shape[0]):     # batch_size\n",
    "        for j in range(half_CWs):\n",
    "            if (x[i,j] == x[i,j+half_CWs]):  # 00 & 11 -> -2*x +1\n",
    "                x[i,j] = (-2*x[i,j]) +1\n",
    "                x[i,j+half_CWs] = (-2*x[i,j+half_CWs]) +1      \n",
    "            if (x[i,j] != x[i,j+half_CWs]):  # 01 & 10 -> 2*x -1\n",
    "                x[i,j] = (2*x[i,j]) -1\n",
    "                x[i,j+half_CWs] = (2*x[i,j+half_CWs]) -1     \n",
    "    return x/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QPSK_modulator(x):\n",
    "    # X = after polar encoding (256,16)\n",
    "    # QPSK step : \n",
    "    # First : 把實部虛部分開，並把虛部丟在實部後面\n",
    "    real = []\n",
    "    imag = []\n",
    "    stack = []\n",
    "    for n in range(x.shape[0]):  # batch-size\n",
    "        for m in range(0, x.shape[1], 2): \n",
    "            stack.append(x[n,m])  # real-part\n",
    "        real.append(stack)\n",
    "        stack = []\n",
    "        for m in range(1, x.shape[1], 2): \n",
    "            stack.append(x[n,m])  # imag-part\n",
    "        imag.append(stack)\n",
    "        stack = []\n",
    "    symbol_np = np.hstack((real, imag))\n",
    "    # Second : NRZ-encoding (0 -> +1 ; 1 -> -1)\n",
    "    # symbol_nrz = (-2*symbol_np +1)/np.sqrt(2)\n",
    "    symbol_nrz = qpsk_NRZ_encoder(symbol_np)\n",
    "    return symbol_nrz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN_addNoise(x, awgn_power):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)                   # real-part\n",
    "            y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)   # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTuning_addNoise(x, awgn_power):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        real_add_impulse = np.random.randint(low=0, high=sym_num)\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            if (j == real_add_impulse) :\n",
    "                IGR = 100              # 高斯脈衝能量比\n",
    "                impulse_power = awgn_power * IGR\n",
    "                y[i,j] = x[i,j] + np.sqrt(impulse_power/2) * np.random.normal(0,1)                  # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(impulse_power/2) * np.random.normal(0,1)  # imag-part\n",
    "            else : \n",
    "                y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)                     # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)     # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_addNoise(x, awgn_power, impulse_prob):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            dice = np.random.uniform(0,1)   # 0~1 隨機選一個小數\n",
    "            if dice <= prob :\n",
    "                IGR = 100              # 高斯脈衝能量比\n",
    "                impulse_power = awgn_power * IGR\n",
    "                y[i,j] = x[i,j] + np.sqrt(impulse_power/2) * np.random.normal(0,1)           # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(impulse_power/2) * np.random.normal(0,1)   # imag-part\n",
    "            else : \n",
    "                y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)              # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)      # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polar Encoder (Bhattacharyya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Algorithm : The Bhattacharyya bounds\n",
    "\"\"\"\n",
    "def polarization_channel_awgn(N, k, design_snr_dB=0):  \n",
    "    design_snr_dB = design_snr_dB +10*np.log10(k/N)\n",
    "    S = 10**(design_snr_dB/10)       # S : R*Eb/N0\n",
    "    n = np.log2(N)                   # N = 2^n\n",
    "    z0 = np.zeros(N)                 # N : Codewords length\n",
    "    # initial the Bhattacharyya parameter of BI-AWGN channel,be replaced with exp(−R*Eb/N0)\n",
    "    z0[0] = np.exp(-S)               # initial erasure-probability of channel        \n",
    "    for j in range(1,int(n)+1):      # How many stage to polarization (output-to-input)\n",
    "        u = 2**j                     # 2^n = N = 幾個 W 副本通道\n",
    "        for t in range(0,int(u/2)):  # For each connection\n",
    "            T = z0[t]\n",
    "            z0[t] = 2*T - T**2       # upper channel (+ channel)\n",
    "            z0[int(u/2)+t] = T**2    # lower channel (- channel)\n",
    "    # sort into increasing order\n",
    "    # z0 array 裝的是每個分離通道的 Prob.Error 數值，\n",
    "    # 數值越大代表通道越糟\n",
    "    #====> 通道由最好排到最差 (左[0]->右[N]) <====#\n",
    "    idx = np.argsort(z0)             \n",
    "    # argsort() 返回的是數組值從小到大的索引值\n",
    "    #====> 通道由最好排到最差 (左[0]->右[N]) <====#\n",
    "    # select k best channels\n",
    "    # 選最好的前半部分通道做 bit-reversal\n",
    "    ######### idx = np.sort(bitrevorder(idx[0:k]))\n",
    "    A = np.zeros(N, dtype=bool)\n",
    "    A[idx[0:k]] = True   # 將 Good_channel 設為可傳 info.\n",
    "    # idx 為 \" 好的通道 \" bit-reversal 後的新通道\n",
    "    return A\n",
    "\n",
    "def polar_xor_encoding(u):  \n",
    "    # 每一組 codewords 為 16-bits , 共 256 組\n",
    "    N = len(u)   # 只看第一維 N = 2**k\n",
    "    n = 1\n",
    "    x = np.copy(u)\n",
    "    stages = np.log2(N).astype(int)   # 通道共分裂成幾階\n",
    "    for s in range(0,stages):         # s = stage\n",
    "        i = 0                         # i = no.of samples\n",
    "        while i < N:                  # N = 256            \n",
    "            for j in range(0,n):      # j always = 0\n",
    "                idx = i+j\n",
    "                x[idx] = x[idx] ^ x[idx+n]  # XOR : Good Channel\n",
    "            i=i+2*n\n",
    "        n=2*n\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_size = 128000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**info_codewords.shape: (128000, 11)\n",
      "**info_codewords: [[1 1 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 1 0 ... 0 1 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 1 0]\n",
      " [1 0 0 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4267)\n",
    "info_codewords = np.random.binomial(n=1, p=0.5, size=(samples_size, k))\n",
    "info_codewords = info_codewords.astype(int)\n",
    "print(\"**info_codewords.shape:\",info_codewords.shape)\n",
    "print(\"**info_codewords:\",info_codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**polar_codewords.shape: (128000, 64)\n",
      "**polar_codewords: [[1 0 0 ... 1 1 0]\n",
      " [1 0 1 ... 1 0 1]\n",
      " [1 0 1 ... 1 0 1]\n",
      " ...\n",
      " [0 0 0 ... 1 1 1]\n",
      " [1 0 1 ... 0 1 0]\n",
      " [1 0 0 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create sets of all possible codewords (codebook)- after encoding\n",
    "# A 代表通道極化後的好與壞 ; u 根據通道好壞決定傳 info. or frozen-0 ; \n",
    "# polar_codewords 是經過多個 stages 編碼後的結果\n",
    "A = polarization_channel_awgn(N, k, design_snr_dB = 0)  \n",
    "# logical vector indicating the nonfrozen bit locations \n",
    "polar_codewords = np.zeros((samples_size, N),dtype=bool)\n",
    "u = np.zeros((samples_size, N),dtype=bool)\n",
    "u[:,A] = info_codewords    # u 只管通道好(True-1)壞(False-0), \n",
    "                  # info_codewords 代表 information-bit 傳 0 or 1\n",
    "# if channel is FALSE 那不管傳 0 or 1 , 都只會傳 0 (Frozen-bit-locations)\n",
    "# if index(A:column first) is bool type -> choose 'True' as index\n",
    "\"\"\"\n",
    "    polar 上半部做通道極化和 frozen-bit-locations 並確定編碼前的 data\n",
    "    polar 下半部做 XOR 編碼動作形成 final codewords\n",
    "\"\"\"\n",
    "for i in range(0,samples_size):\n",
    "    polar_codewords[i] = polar_xor_encoding(u[i])   # (boolean -> int)\n",
    "    # 通道建好後丟 information-bits 進去編成最終的 polar encoding codewords \n",
    "polar_codewords = polar_codewords.astype(int)\n",
    "print(\"**polar_codewords.shape:\",polar_codewords.shape)\n",
    "print(\"**polar_codewords:\",polar_codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Torch NN Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**decoder_model: DNN_Model(\n",
      "  (fcnn1): Linear(in_features=64, out_features=1500, bias=True)\n",
      "  (fcnn2): Linear(in_features=1500, out_features=1500, bias=True)\n",
      "  (fcnn3): Linear(in_features=1500, out_features=1200, bias=True)\n",
      "  (fcnn4): Linear(in_features=1200, out_features=1000, bias=True)\n",
      "  (output): Linear(in_features=1000, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_Model, self).__init__()\n",
    "        self.fcnn1 = nn.Linear(N, 1500)                  # 第1層 Linear NN\n",
    "        self.fcnn2 = nn.Linear(1500, 1500)                # 第2層 Linear NN\n",
    "        self.fcnn3 = nn.Linear(1500, 1200)                 # 第3層 Linear NN\n",
    "        self.fcnn4 = nn.Linear(1200, 1000)                 # 第3層 Linear NN\n",
    "        self.output = nn.Linear(1000, k)                  # 第4層 Linear NN\n",
    "        # nn.init.kaiming_normal_(self.fcnn2.weight, mode='fan_in')     \n",
    "        # nn.init.normal_(self.fcnn4.bias, mean=0.0, std=0.1)\n",
    "\n",
    "    def forward(self, input_layer):\n",
    "        x = F.relu(self.fcnn1(input_layer))\n",
    "        x = F.relu(self.fcnn2(x))\n",
    "        x = F.relu(self.fcnn3(x))\n",
    "        x = F.relu(self.fcnn4(x))\n",
    "        predi_output = torch.sigmoid(self.output(x))\n",
    "        return predi_output\n",
    "        \n",
    "decoder = DNN_Model()                      # build the DNN Model\n",
    "print(\"**decoder_model:\",decoder)          # 將模型print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for AWGN Noise\n",
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_Model(\n",
       "  (fcnn1): Linear(in_features=64, out_features=1500, bias=True)\n",
       "  (fcnn2): Linear(in_features=1500, out_features=1500, bias=True)\n",
       "  (fcnn3): Linear(in_features=1500, out_features=1200, bias=True)\n",
       "  (fcnn4): Linear(in_features=1200, out_features=1000, bias=True)\n",
       "  (output): Linear(in_features=1000, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights\n",
    "decoder.load_state_dict(torch.load('AWGN_4-layerNN_V9__0-dB.pt'))\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def mini_batch_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    batch_loss.backward()                   # 反向传播求梯度\n",
    "    optimizer.step()                        # 更新所有参数\n",
    "    return batch_loss.detach()\n",
    "\n",
    "def validation_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    return batch_loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "#================================ start_training ================================#\n",
      "----------------------------------------------------------------------------------\n",
      "#=================> epoch: 1 <=================#\n",
      "**Epoch_training_cost: tensor(0.0386)\n",
      "**Epoch_valid_cost: tensor(0.0088)\n",
      "#=================> epoch: 2 <=================#\n",
      "**Epoch_training_cost: tensor(0.0338)\n",
      "**Epoch_valid_cost: tensor(0.0078)\n",
      "#=================> epoch: 3 <=================#\n",
      "**Epoch_training_cost: tensor(0.0315)\n",
      "**Epoch_valid_cost: tensor(0.0074)\n",
      "#=================> epoch: 4 <=================#\n",
      "**Epoch_training_cost: tensor(0.0291)\n",
      "**Epoch_valid_cost: tensor(0.0069)\n",
      "#=================> epoch: 5 <=================#\n",
      "**Epoch_training_cost: tensor(0.0271)\n",
      "**Epoch_valid_cost: tensor(0.0066)\n",
      "#=================> epoch: 6 <=================#\n",
      "**Epoch_training_cost: tensor(0.0247)\n",
      "**Epoch_valid_cost: tensor(0.0057)\n",
      "#=================> epoch: 7 <=================#\n",
      "**Epoch_training_cost: tensor(0.0229)\n",
      "**Epoch_valid_cost: tensor(0.0053)\n",
      "#=================> epoch: 8 <=================#\n",
      "**Epoch_training_cost: tensor(0.0205)\n",
      "**Epoch_valid_cost: tensor(0.0049)\n",
      "#=================> epoch: 9 <=================#\n",
      "**Epoch_training_cost: tensor(0.0188)\n",
      "**Epoch_valid_cost: tensor(0.0045)\n",
      "#=================> epoch: 10 <=================#\n",
      "**Epoch_training_cost: tensor(0.0165)\n",
      "**Epoch_valid_cost: tensor(0.0039)\n",
      "#=================> epoch: 11 <=================#\n",
      "**Epoch_training_cost: tensor(0.0153)\n",
      "**Epoch_valid_cost: tensor(0.0035)\n",
      "#=================> epoch: 12 <=================#\n",
      "**Epoch_training_cost: tensor(0.0138)\n",
      "**Epoch_valid_cost: tensor(0.0033)\n",
      "#=================> epoch: 13 <=================#\n",
      "**Epoch_training_cost: tensor(0.0125)\n",
      "**Epoch_valid_cost: tensor(0.0028)\n",
      "#=================> epoch: 14 <=================#\n",
      "**Epoch_training_cost: tensor(0.0112)\n",
      "**Epoch_valid_cost: tensor(0.0027)\n",
      "#=================> epoch: 15 <=================#\n",
      "**Epoch_training_cost: tensor(0.0102)\n",
      "**Epoch_valid_cost: tensor(0.0025)\n",
      "#=================> epoch: 16 <=================#\n",
      "**Epoch_training_cost: tensor(0.0095)\n",
      "**Epoch_valid_cost: tensor(0.0022)\n",
      "#=================> epoch: 17 <=================#\n",
      "**Epoch_training_cost: tensor(0.0087)\n",
      "**Epoch_valid_cost: tensor(0.0020)\n",
      "#=================> epoch: 18 <=================#\n",
      "**Epoch_training_cost: tensor(0.0081)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 19 <=================#\n",
      "**Epoch_training_cost: tensor(0.0077)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 20 <=================#\n",
      "**Epoch_training_cost: tensor(0.0072)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 21 <=================#\n",
      "**Epoch_training_cost: tensor(0.0068)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 22 <=================#\n",
      "**Epoch_training_cost: tensor(0.0063)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 23 <=================#\n",
      "**Epoch_training_cost: tensor(0.0059)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 24 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 25 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 26 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 27 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 28 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 29 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 30 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 31 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 32 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 33 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 34 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 35 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 36 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 37 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 38 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 39 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 40 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 41 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 42 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 43 <=================#\n",
      "**Epoch_training_cost: tensor(0.0035)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 44 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 45 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 46 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 47 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 48 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 49 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 50 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 51 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 52 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 53 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 54 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 55 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 56 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 57 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 58 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 59 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 60 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 61 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 62 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 63 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 64 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 65 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 66 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 67 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 68 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 69 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 70 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 71 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 72 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 73 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 74 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 75 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 76 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 77 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 78 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 79 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 80 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 81 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 82 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 83 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 84 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 85 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 86 <=================#\n",
      "**Epoch_training_cost: tensor(0.0025)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 87 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 88 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 89 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 90 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 91 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 92 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 93 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 94 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 95 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 96 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 97 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 98 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 99 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 100 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 101 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 102 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 103 <=================#\n",
      "**Epoch_training_cost: tensor(0.0024)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 104 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 105 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 106 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 107 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 108 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 109 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 110 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 111 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 112 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 113 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 114 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 115 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 116 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 117 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 118 <=================#\n",
      "**Epoch_training_cost: tensor(0.0023)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 119 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 120 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 121 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 122 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 123 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 124 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 125 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 126 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 127 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 128 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 129 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 130 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 131 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 132 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 133 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 134 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 135 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 136 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 137 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 138 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 139 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 140 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 141 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 142 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 143 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 144 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 145 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 146 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 147 <=================#\n",
      "**Epoch_training_cost: tensor(0.0022)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 148 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 149 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 150 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 151 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 152 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 153 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 154 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 155 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 156 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 157 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 158 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 159 <=================#\n",
      "**Epoch_training_cost: tensor(0.0021)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 160 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 161 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 162 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 163 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 164 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 165 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 166 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 167 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 168 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 169 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 170 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 171 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 172 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 173 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 174 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 175 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 176 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 177 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 178 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 179 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 180 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 181 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 182 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 183 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 184 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 185 <=================#\n",
      "**Epoch_training_cost: tensor(0.0020)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 186 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 187 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 188 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 189 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 190 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 191 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 192 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 193 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 194 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 195 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 196 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 197 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 198 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 199 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 200 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 201 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 202 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 203 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 204 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 205 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 206 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 207 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 208 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 209 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 210 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 211 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 212 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 213 <=================#\n",
      "**Epoch_training_cost: tensor(0.0019)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 214 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 215 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 216 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 217 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 218 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 219 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 220 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 221 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 222 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 223 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 224 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 225 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 226 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 227 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 228 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 229 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 230 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 231 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 232 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 233 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 234 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 235 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 236 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 237 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 238 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 239 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 240 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 241 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 242 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 243 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 244 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 245 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 246 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 247 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 248 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 249 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 250 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 251 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 252 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 253 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 254 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 255 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 256 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 257 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 258 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 259 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 260 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 261 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 262 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 263 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 264 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 265 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 266 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 267 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 268 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 269 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 270 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 271 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 272 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 273 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 274 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 275 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 276 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 277 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 278 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 279 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 280 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 281 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 282 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 283 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 284 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 285 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 286 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 287 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 288 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 289 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 290 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 291 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 292 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 293 <=================#\n",
      "**Epoch_training_cost: tensor(0.0018)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 294 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 295 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 296 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 297 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 298 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 299 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 300 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 301 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 302 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 303 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 304 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 305 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 306 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 307 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 308 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 309 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 310 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 311 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 312 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 313 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 314 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 315 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 316 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 317 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 318 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 319 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 320 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 321 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 322 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 323 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 324 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 325 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 326 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 327 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 328 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 329 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 330 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 331 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 332 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 333 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 334 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 335 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 336 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 337 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 338 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 339 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 340 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 341 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 342 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 343 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 344 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 345 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 346 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 347 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 348 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 349 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 350 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 351 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 352 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 353 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 354 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 355 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 356 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 357 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 358 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 359 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0005)\n",
      "#=================> epoch: 360 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 361 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 362 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 363 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 364 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 365 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 366 <=================#\n",
      "**Epoch_training_cost: tensor(0.0017)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 367 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 368 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 369 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 370 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 371 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 372 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 373 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 374 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 375 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 376 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 377 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 378 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 379 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 380 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 381 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 382 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 383 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 384 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 385 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 386 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 387 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 388 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 389 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 390 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 391 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 392 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 393 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 394 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 395 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 396 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 397 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 398 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 399 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 400 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 401 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 402 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 403 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 404 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 405 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 406 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 407 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 408 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 409 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 410 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 411 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 412 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 413 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 414 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 415 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 416 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 417 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 418 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 419 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 420 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 421 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 422 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 423 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 424 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 425 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 426 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 427 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 428 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 429 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 430 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 431 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 432 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 433 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 434 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 435 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 436 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 437 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 438 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 439 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 440 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 441 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 442 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 443 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 444 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 445 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 446 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 447 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 448 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 449 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 450 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 451 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 452 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 453 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 454 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 455 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 456 <=================#\n",
      "**Epoch_training_cost: tensor(0.0016)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 457 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 458 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 459 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 460 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 461 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 462 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 463 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 464 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 465 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 466 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 467 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 468 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 469 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 470 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 471 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 472 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 473 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 474 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 475 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 476 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 477 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 478 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 479 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 480 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 481 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 482 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 483 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 484 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 485 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 486 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 487 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 488 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 489 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 490 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 491 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 492 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 493 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 494 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 495 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 496 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 497 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n",
      "#=================> epoch: 498 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 499 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 500 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 501 <=================#\n",
      "**Epoch_training_cost: tensor(0.0015)\n",
      "**Epoch_valid_cost: tensor(0.0004)\n"
     ]
    }
   ],
   "source": [
    "training_1, validate_1 = [], []\n",
    "training_batch = samples_size * 0.8\n",
    "valid_batch = samples_size * 0.2\n",
    "mini_batch = 512\n",
    "total_iterations = int(training_batch/mini_batch)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"#================================ start_training ================================#\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "for epoch in range(0, 501):\n",
    "    print(\"#=================> epoch:\",epoch+1,\"<=================#\")\n",
    "    ## ======== Training ======== ##\n",
    "    batch_cost = 0\n",
    "    for iteration in range(0, total_iterations):\n",
    "        x, y = iteration*mini_batch , ((iteration+1)*mini_batch)\n",
    "        ##print(\"**iteration:\", iteration+1)\n",
    "        ##print(\"[ index:\",tr_x , \"~ index:\",tr_y, \"]\")\n",
    "        ##print(\"polar_codewords.shape\",polar_codewords[x:y].shape)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = mini_batch_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_training_cost:\", avg_batch_cost)\n",
    "    training_1.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)\n",
    "    batch_cost = 0\n",
    "    ## ======== Validation ======== ##\n",
    "    for valid_idx in range(201, 250):\n",
    "        x, y = valid_idx*mini_batch , ((valid_idx+1)*mini_batch)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = validation_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_valid_cost:\", avg_batch_cost)\n",
    "    validate_1.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save \n",
    "torch.save(decoder, 'FT_4-layerNN_V9__4-dB.pt') \n",
    "# model save weight\n",
    "torch.save(decoder.state_dict(), 'FT_4-layerNN_V9__4-dB.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_1: [tensor(0.0386), tensor(0.0338), tensor(0.0315), tensor(0.0291), tensor(0.0271), tensor(0.0247), tensor(0.0229), tensor(0.0205), tensor(0.0188), tensor(0.0165), tensor(0.0153), tensor(0.0138), tensor(0.0125), tensor(0.0112), tensor(0.0102), tensor(0.0095), tensor(0.0087), tensor(0.0081), tensor(0.0077), tensor(0.0072), tensor(0.0068), tensor(0.0063), tensor(0.0059), tensor(0.0060), tensor(0.0055), tensor(0.0052), tensor(0.0050), tensor(0.0048), tensor(0.0047), tensor(0.0045), tensor(0.0046), tensor(0.0043), tensor(0.0042), tensor(0.0042), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0037), tensor(0.0034), tensor(0.0036), tensor(0.0035), tensor(0.0033), tensor(0.0033), tensor(0.0033), tensor(0.0032), tensor(0.0032), tensor(0.0031), tensor(0.0032), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0027), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0026), tensor(0.0027), tensor(0.0027), tensor(0.0027), tensor(0.0026), tensor(0.0026), tensor(0.0027), tensor(0.0027), tensor(0.0026), tensor(0.0026), tensor(0.0025), tensor(0.0026), tensor(0.0025), tensor(0.0025), tensor(0.0026), tensor(0.0024), tensor(0.0024), tensor(0.0024), tensor(0.0023), tensor(0.0025), tensor(0.0025), tensor(0.0025), tensor(0.0025), tensor(0.0024), tensor(0.0024), tensor(0.0023), tensor(0.0024), tensor(0.0024), tensor(0.0024), tensor(0.0023), tensor(0.0024), tensor(0.0023), tensor(0.0024), tensor(0.0024), tensor(0.0023), tensor(0.0024), tensor(0.0023), tensor(0.0022), tensor(0.0022), tensor(0.0024), tensor(0.0023), tensor(0.0023), tensor(0.0022), tensor(0.0021), tensor(0.0022), tensor(0.0022), tensor(0.0023), tensor(0.0021), tensor(0.0022), tensor(0.0022), tensor(0.0022), tensor(0.0022), tensor(0.0022), tensor(0.0022), tensor(0.0023), tensor(0.0022), tensor(0.0021), tensor(0.0022), tensor(0.0020), tensor(0.0022), tensor(0.0021), tensor(0.0021), tensor(0.0022), tensor(0.0022), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0021), tensor(0.0020), tensor(0.0020), tensor(0.0021), tensor(0.0020), tensor(0.0021), tensor(0.0021), tensor(0.0020), tensor(0.0021), tensor(0.0022), tensor(0.0019), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0021), tensor(0.0020), tensor(0.0020), tensor(0.0019), tensor(0.0020), tensor(0.0019), tensor(0.0020), tensor(0.0021), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0020), tensor(0.0020), tensor(0.0019), tensor(0.0020), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0020), tensor(0.0019), tensor(0.0019), tensor(0.0017), tensor(0.0019), tensor(0.0020), tensor(0.0018), tensor(0.0018), tensor(0.0020), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0018), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0019), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0016), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0016), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0018), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0015), tensor(0.0017), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0016), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0016), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0013), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0016), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0014), tensor(0.0013), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0013), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0015)]\n"
     ]
    }
   ],
   "source": [
    "print(\"training_1:\",training_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_1: [tensor(0.0088), tensor(0.0078), tensor(0.0074), tensor(0.0069), tensor(0.0066), tensor(0.0057), tensor(0.0053), tensor(0.0049), tensor(0.0045), tensor(0.0039), tensor(0.0035), tensor(0.0033), tensor(0.0028), tensor(0.0027), tensor(0.0025), tensor(0.0022), tensor(0.0020), tensor(0.0019), tensor(0.0018), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0013), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0008), tensor(0.0009), tensor(0.0009), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0007), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0006), tensor(0.0007), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0007), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0006), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0006), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0005), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0005), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0004), tensor(0.0004), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0004)]\n"
     ]
    }
   ],
   "source": [
    "print(\"validate_1:\",validate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "#decoder.load_state_dict(torch.load('AWGN_4-layerNN_V7__0-dB.pt'))\n",
    "#decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-5)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def mini_batch_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    batch_loss.backward()                   # 反向传播求梯度\n",
    "    optimizer.step()                        # 更新所有参数\n",
    "    return batch_loss.detach()\n",
    "\n",
    "def validation_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    return batch_loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "#================================ start_training ================================#\n",
      "----------------------------------------------------------------------------------\n",
      "#=================> epoch: 1 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 2 <=================#\n",
      "**Epoch_training_cost: tensor(0.0014)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 3 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 4 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 5 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 6 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 7 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 8 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 9 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 10 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 11 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 12 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 13 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 14 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 15 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 16 <=================#\n",
      "**Epoch_training_cost: tensor(0.0013)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 17 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 18 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 19 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 20 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 21 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 22 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 23 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 24 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 25 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 26 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 27 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 28 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 29 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 30 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 31 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 32 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 33 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 34 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 35 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 36 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 37 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 38 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 39 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 40 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 41 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 42 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 43 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 44 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 45 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 46 <=================#\n",
      "**Epoch_training_cost: tensor(0.0012)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 47 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 48 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 49 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 50 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 51 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 52 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 53 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 54 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 55 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 56 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 57 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 58 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 59 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 60 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 61 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 62 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 63 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 64 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 65 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 66 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 67 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 68 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 69 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 70 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 71 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 72 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 73 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 74 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 75 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 76 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 77 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 78 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 79 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 80 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 81 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 82 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 83 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 84 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 85 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 86 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 87 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 88 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 89 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 90 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 91 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 92 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 93 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 94 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 95 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 96 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 97 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 98 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 99 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 100 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 101 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 102 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 103 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 104 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 105 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 106 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 107 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 108 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 109 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 110 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 111 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 112 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 113 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 114 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 115 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 116 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 117 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 118 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 119 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 120 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 121 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 122 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 123 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 124 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 125 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 126 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 127 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 128 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 129 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 130 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 131 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 132 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 133 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 134 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 135 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 136 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 137 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 138 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 139 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 140 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 141 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 142 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 143 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 144 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 145 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 146 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 147 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 148 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 149 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 150 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 151 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 152 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 153 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 154 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 155 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 156 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 157 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 158 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 159 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 160 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 161 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 162 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 163 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 164 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 165 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 166 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 167 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 168 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 169 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 170 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 171 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 172 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 173 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 174 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 175 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 176 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 177 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 178 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 179 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 180 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 181 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 182 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 183 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 184 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 185 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 186 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 187 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 188 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 189 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 190 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 191 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 192 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 193 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 194 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 195 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 196 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 197 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 198 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 199 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 200 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 201 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 202 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 203 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 204 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 205 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 206 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 207 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 208 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 209 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 210 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 211 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 212 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 213 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 214 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 215 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 216 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 217 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 218 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 219 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 220 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 221 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 222 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 223 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 224 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 225 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 226 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 227 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 228 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 229 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 230 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 231 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 232 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 233 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 234 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 235 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 236 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 237 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 238 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 239 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 240 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 241 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 242 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 243 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 244 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 245 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 246 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 247 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 248 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 249 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 250 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 251 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 252 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 253 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 254 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 255 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 256 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 257 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 258 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 259 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 260 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 261 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 262 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 263 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 264 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 265 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 266 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 267 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 268 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 269 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 270 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 271 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 272 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 273 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 274 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 275 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 276 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 277 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 278 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 279 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 280 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 281 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 282 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 283 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 284 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 285 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 286 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 287 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 288 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 289 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 290 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 291 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 292 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 293 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 294 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 295 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 296 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 297 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 298 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 299 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 300 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 301 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 302 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 303 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 304 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 305 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 306 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 307 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 308 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 309 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 310 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 311 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 312 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 313 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 314 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 315 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 316 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 317 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 318 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 319 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 320 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 321 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 322 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 323 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 324 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 325 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 326 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 327 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 328 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 329 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 330 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 331 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 332 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 333 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 334 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 335 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 336 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 337 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 338 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 339 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 340 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 341 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 342 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 343 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 344 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 345 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 346 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 347 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 348 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 349 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 350 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 351 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 352 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 353 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 354 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 355 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 356 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 357 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 358 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 359 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 360 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 361 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 362 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 363 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 364 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 365 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 366 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 367 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 368 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 369 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 370 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 371 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 372 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 373 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 374 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 375 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 376 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 377 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 378 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 379 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 380 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 381 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 382 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 383 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 384 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 385 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 386 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 387 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 388 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 389 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 390 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 391 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 392 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 393 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 394 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 395 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 396 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 397 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 398 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 399 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 400 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 401 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 402 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 403 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 404 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 405 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 406 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 407 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 408 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 409 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 410 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 411 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 412 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 413 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 414 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 415 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 416 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 417 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 418 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 419 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 420 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 421 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 422 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 423 <=================#\n",
      "**Epoch_training_cost: tensor(0.0011)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 424 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 425 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 426 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 427 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 428 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 429 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 430 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 431 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 432 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 433 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 434 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 435 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 436 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 437 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 438 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 439 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 440 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 441 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 442 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 443 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 444 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 445 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 446 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 447 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 448 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 449 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 450 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 451 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 452 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 453 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 454 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 455 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 456 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 457 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 458 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 459 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 460 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 461 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 462 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 463 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 464 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 465 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 466 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 467 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 468 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 469 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 470 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 471 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 472 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 473 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 474 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 475 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 476 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 477 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 478 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 479 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 480 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 481 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 482 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 483 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 484 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 485 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 486 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 487 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 488 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 489 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 490 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 491 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 492 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 493 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 494 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 495 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 496 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 497 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 498 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 499 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n",
      "#=================> epoch: 500 <=================#\n",
      "**Epoch_training_cost: tensor(0.0010)\n",
      "**Epoch_valid_cost: tensor(0.0003)\n",
      "#=================> epoch: 501 <=================#\n",
      "**Epoch_training_cost: tensor(0.0009)\n",
      "**Epoch_valid_cost: tensor(0.0002)\n"
     ]
    }
   ],
   "source": [
    "training_2, validate_2 = [], []\n",
    "training_batch = samples_size * 0.8\n",
    "valid_batch = samples_size * 0.2\n",
    "mini_batch = 512\n",
    "total_iterations = int(training_batch/mini_batch)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"#================================ start_training ================================#\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "for epoch in range(0, 501):\n",
    "    print(\"#=================> epoch:\",epoch+1,\"<=================#\")\n",
    "    ## ======== Training ======== ##\n",
    "    batch_cost = 0\n",
    "    for iteration in range(0, total_iterations):\n",
    "        x, y = iteration*mini_batch , ((iteration+1)*mini_batch)\n",
    "        ##print(\"**iteration:\", iteration+1)\n",
    "        ##print(\"[ index:\",tr_x , \"~ index:\",tr_y, \"]\")\n",
    "        ##print(\"polar_codewords.shape\",polar_codewords[x:y].shape)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = mini_batch_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_training_cost:\", avg_batch_cost)\n",
    "    training_2.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)\n",
    "    batch_cost = 0\n",
    "    ## ======== Validation ======== ##\n",
    "    for valid_idx in range(201, 250):\n",
    "        x, y = valid_idx*mini_batch , ((valid_idx+1)*mini_batch)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = validation_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_valid_cost:\", avg_batch_cost)\n",
    "    validate_2.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save \n",
    "torch.save(decoder, 'FT_4-layerNN_V9__4-dB.pt') \n",
    "# model save weight\n",
    "torch.save(decoder.state_dict(), 'FT_4-layerNN_V9__4-dB.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_2: [tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0012), tensor(0.0011), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009)]\n"
     ]
    }
   ],
   "source": [
    "print(\"training_2:\",training_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_2: [tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002), tensor(0.0003), tensor(0.0003), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0002), tensor(0.0003), tensor(0.0002)]\n"
     ]
    }
   ],
   "source": [
    "print(\"validate_2:\",validate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# No Smoothing :\n",
    "legend = []\n",
    "total_training_loss = training_1 + training_2 + training_3\n",
    "total_valid_loss = validate_1 + validate_2 + validate_3\n",
    "plt.plot(torch.Tensor(total_training_loss).detach().numpy(), linewidth = '2.5', linestyle='--')\n",
    "legend.append(\"Training_loss\")\n",
    "plt.plot(torch.Tensor(total_valid_loss).detach().numpy()*4, linewidth = '2.5', linestyle='--')\n",
    "legend.append(\"Validation_loss\")\n",
    "plt.title('Model loss', fontsize=17)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "## plt.legend(['Fine-Tuning Training-Loss'], fontsize=15)\n",
    "plt.legend(legend, loc = 0, fontsize=15)\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
