{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN_Polar_Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "%matplotlib inline\n",
    "import gc\n",
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_power: 1.0023744672545447\n",
      "noise_sigma: 0.7079457843841379\n"
     ]
    }
   ],
   "source": [
    "k = 11\n",
    "N = 64\n",
    "R = k/N\n",
    "SNR_dB = 3     \n",
    "noise_power = 1/10**(SNR_dB/10)\n",
    "noise_power = noise_power * 2\n",
    "print(\"noise_power:\", noise_power)    # 1/2*No\n",
    "print(\"noise_sigma:\", np.sqrt(noise_power/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Noise & Modulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPSK_modulator(x):\n",
    "    return -2*x +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qpsk_NRZ_encoder(x):\n",
    "    half_CWs = int(x.shape[1]/2)    # half codewords length\n",
    "    for i in range(x.shape[0]):     # batch_size\n",
    "        for j in range(half_CWs):\n",
    "            if (x[i,j] == x[i,j+half_CWs]):  # 00 & 11 -> -2*x +1\n",
    "                x[i,j] = (-2*x[i,j]) +1\n",
    "                x[i,j+half_CWs] = (-2*x[i,j+half_CWs]) +1      \n",
    "            if (x[i,j] != x[i,j+half_CWs]):  # 01 & 10 -> 2*x -1\n",
    "                x[i,j] = (2*x[i,j]) -1\n",
    "                x[i,j+half_CWs] = (2*x[i,j+half_CWs]) -1     \n",
    "    return x/np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QPSK_modulator(x):\n",
    "    # X = after polar encoding (256,16)\n",
    "    # QPSK step : \n",
    "    # First : 把實部虛部分開，並把虛部丟在實部後面\n",
    "    real = []\n",
    "    imag = []\n",
    "    stack = []\n",
    "    for n in range(x.shape[0]):  # batch-size\n",
    "        for m in range(0, x.shape[1], 2): \n",
    "            stack.append(x[n,m])  # real-part\n",
    "        real.append(stack)\n",
    "        stack = []\n",
    "        for m in range(1, x.shape[1], 2): \n",
    "            stack.append(x[n,m])  # imag-part\n",
    "        imag.append(stack)\n",
    "        stack = []\n",
    "    symbol_np = np.hstack((real, imag))\n",
    "    # Second : NRZ-encoding (0 -> +1 ; 1 -> -1)\n",
    "    # symbol_nrz = (-2*symbol_np +1)/np.sqrt(2)\n",
    "    symbol_nrz = qpsk_NRZ_encoder(symbol_np)\n",
    "    return symbol_nrz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AWGN_addNoise(x, awgn_power):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)                   # real-part\n",
    "            y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)   # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTuning_addNoise(x, awgn_power):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        real_add_impulse = np.random.randint(low=0, high=sym_num)\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            if (j == real_add_impulse) :\n",
    "                IGR = 100              # 高斯脈衝能量比\n",
    "                impulse_power = awgn_power * IGR\n",
    "                y[i,j] = x[i,j] + np.sqrt(impulse_power/2) * np.random.normal(0,1)                  # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(impulse_power/2) * np.random.normal(0,1)  # imag-part\n",
    "            else : \n",
    "                y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)                     # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)     # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_addNoise(x, awgn_power, impulse_prob):\n",
    "    sym_num = int(x.shape[1]/2)\n",
    "    y = np.zeros((x.shape[0],x.shape[1]))\n",
    "    for i in range (x.shape[0]):       # batch-size\n",
    "        for j in range (sym_num):      # no_of_bits\n",
    "            dice = np.random.uniform(0,1)   # 0~1 隨機選一個小數\n",
    "            if dice <= prob :\n",
    "                IGR = 100              # 高斯脈衝能量比\n",
    "                impulse_power = awgn_power * IGR\n",
    "                y[i,j] = x[i,j] + np.sqrt(impulse_power/2) * np.random.normal(0,1)           # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(impulse_power/2) * np.random.normal(0,1)   # imag-part\n",
    "            else : \n",
    "                y[i,j] = x[i,j] + np.sqrt(awgn_power/2) * np.random.normal(0,1)              # real-part\n",
    "                y[i,j+sym_num] = x[i,j+sym_num] + np.sqrt(awgn_power/2) * np.random.normal(0,1)      # imag-part\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polar Encoder (Bhattacharyya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Algorithm : The Bhattacharyya bounds\n",
    "\"\"\"\n",
    "def polarization_channel_awgn(N, k, design_snr_dB=0):  \n",
    "    design_snr_dB = design_snr_dB +10*np.log10(k/N)\n",
    "    S = 10**(design_snr_dB/10)       # S : R*Eb/N0\n",
    "    n = np.log2(N)                   # N = 2^n\n",
    "    z0 = np.zeros(N)                 # N : Codewords length\n",
    "    # initial the Bhattacharyya parameter of BI-AWGN channel,be replaced with exp(−R*Eb/N0)\n",
    "    z0[0] = np.exp(-S)               # initial erasure-probability of channel        \n",
    "    for j in range(1,int(n)+1):      # How many stage to polarization (output-to-input)\n",
    "        u = 2**j                     # 2^n = N = 幾個 W 副本通道\n",
    "        for t in range(0,int(u/2)):  # For each connection\n",
    "            T = z0[t]\n",
    "            z0[t] = 2*T - T**2       # upper channel (+ channel)\n",
    "            z0[int(u/2)+t] = T**2    # lower channel (- channel)\n",
    "    # sort into increasing order\n",
    "    # z0 array 裝的是每個分離通道的 Prob.Error 數值，\n",
    "    # 數值越大代表通道越糟\n",
    "    #====> 通道由最好排到最差 (左[0]->右[N]) <====#\n",
    "    idx = np.argsort(z0)             \n",
    "    # argsort() 返回的是數組值從小到大的索引值\n",
    "    #====> 通道由最好排到最差 (左[0]->右[N]) <====#\n",
    "    # select k best channels\n",
    "    # 選最好的前半部分通道做 bit-reversal\n",
    "    ######### idx = np.sort(bitrevorder(idx[0:k]))\n",
    "    A = np.zeros(N, dtype=bool)\n",
    "    A[idx[0:k]] = True   # 將 Good_channel 設為可傳 info.\n",
    "    # idx 為 \" 好的通道 \" bit-reversal 後的新通道\n",
    "    return A\n",
    "\n",
    "def polar_xor_encoding(u):  \n",
    "    # 每一組 codewords 為 16-bits , 共 256 組\n",
    "    N = len(u)   # 只看第一維 N = 2**k\n",
    "    n = 1\n",
    "    x = np.copy(u)\n",
    "    stages = np.log2(N).astype(int)   # 通道共分裂成幾階\n",
    "    for s in range(0,stages):         # s = stage\n",
    "        i = 0                         # i = no.of samples\n",
    "        while i < N:                  # N = 256            \n",
    "            for j in range(0,n):      # j always = 0\n",
    "                idx = i+j\n",
    "                x[idx] = x[idx] ^ x[idx+n]  # XOR : Good Channel\n",
    "            i=i+2*n\n",
    "        n=2*n\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_size = 128000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**info_codewords.shape: (128000, 11)\n",
      "**info_codewords: [[1 1 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 1 0 ... 0 1 1]\n",
      " ...\n",
      " [1 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 1 0]\n",
      " [1 0 0 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4267)\n",
    "info_codewords = np.random.binomial(n=1, p=0.5, size=(samples_size, k))\n",
    "info_codewords = info_codewords.astype(int)\n",
    "print(\"**info_codewords.shape:\",info_codewords.shape)\n",
    "print(\"**info_codewords:\",info_codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**polar_codewords.shape: (128000, 64)\n",
      "**polar_codewords: [[1 0 0 ... 1 1 0]\n",
      " [1 0 1 ... 1 0 1]\n",
      " [1 0 1 ... 1 0 1]\n",
      " ...\n",
      " [0 0 0 ... 1 1 1]\n",
      " [1 0 1 ... 0 1 0]\n",
      " [1 0 0 ... 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create sets of all possible codewords (codebook)- after encoding\n",
    "# A 代表通道極化後的好與壞 ; u 根據通道好壞決定傳 info. or frozen-0 ; \n",
    "# polar_codewords 是經過多個 stages 編碼後的結果\n",
    "A = polarization_channel_awgn(N, k, design_snr_dB = 0)  \n",
    "# logical vector indicating the nonfrozen bit locations \n",
    "polar_codewords = np.zeros((samples_size, N),dtype=bool)\n",
    "u = np.zeros((samples_size, N),dtype=bool)\n",
    "u[:,A] = info_codewords    # u 只管通道好(True-1)壞(False-0), \n",
    "                  # info_codewords 代表 information-bit 傳 0 or 1\n",
    "# if channel is FALSE 那不管傳 0 or 1 , 都只會傳 0 (Frozen-bit-locations)\n",
    "# if index(A:column first) is bool type -> choose 'True' as index\n",
    "\"\"\"\n",
    "    polar 上半部做通道極化和 frozen-bit-locations 並確定編碼前的 data\n",
    "    polar 下半部做 XOR 編碼動作形成 final codewords\n",
    "\"\"\"\n",
    "for i in range(0,samples_size):\n",
    "    polar_codewords[i] = polar_xor_encoding(u[i])   # (boolean -> int)\n",
    "    # 通道建好後丟 information-bits 進去編成最終的 polar encoding codewords \n",
    "polar_codewords = polar_codewords.astype(int)\n",
    "print(\"**polar_codewords.shape:\",polar_codewords.shape)\n",
    "print(\"**polar_codewords:\",polar_codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Torch NN Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**decoder_model: DNN_Model(\n",
      "  (fcnn1): Linear(in_features=64, out_features=1500, bias=True)\n",
      "  (fcnn2): Linear(in_features=1500, out_features=1500, bias=True)\n",
      "  (fcnn3): Linear(in_features=1500, out_features=1200, bias=True)\n",
      "  (fcnn4): Linear(in_features=1200, out_features=1000, bias=True)\n",
      "  (output): Linear(in_features=1000, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_Model, self).__init__()\n",
    "        self.fcnn1 = nn.Linear(N, 1500)                  # 第1層 Linear NN\n",
    "        self.fcnn2 = nn.Linear(1500, 1500)                # 第2層 Linear NN\n",
    "        self.fcnn3 = nn.Linear(1500, 1200)                 # 第3層 Linear NN\n",
    "        self.fcnn4 = nn.Linear(1200, 1000)                 # 第3層 Linear NN\n",
    "        self.output = nn.Linear(1000, k)                  # 第4層 Linear NN\n",
    "        # nn.init.kaiming_normal_(self.fcnn2.weight, mode='fan_in')     \n",
    "        # nn.init.normal_(self.fcnn4.bias, mean=0.0, std=0.1)\n",
    "\n",
    "    def forward(self, input_layer):\n",
    "        x = F.relu(self.fcnn1(input_layer))\n",
    "        x = F.relu(self.fcnn2(x))\n",
    "        x = F.relu(self.fcnn3(x))\n",
    "        x = F.relu(self.fcnn4(x))\n",
    "        predi_output = torch.sigmoid(self.output(x))\n",
    "        return predi_output\n",
    "        \n",
    "decoder = DNN_Model()                      # build the DNN Model\n",
    "print(\"**decoder_model:\",decoder)          # 將模型print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for AWGN Noise\n",
    "np.random.seed(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_Model(\n",
       "  (fcnn1): Linear(in_features=64, out_features=1500, bias=True)\n",
       "  (fcnn2): Linear(in_features=1500, out_features=1500, bias=True)\n",
       "  (fcnn3): Linear(in_features=1500, out_features=1200, bias=True)\n",
       "  (fcnn4): Linear(in_features=1200, out_features=1000, bias=True)\n",
       "  (output): Linear(in_features=1000, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights\n",
    "decoder.load_state_dict(torch.load('AWGN_4-layerNN_V9__0-dB.pt'))\n",
    "decoder.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def mini_batch_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    batch_loss.backward()                   # 反向传播求梯度\n",
    "    optimizer.step()                        # 更新所有参数\n",
    "    return batch_loss.detach()\n",
    "\n",
    "def validation_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    return batch_loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "#================================ start_training ================================#\n",
      "----------------------------------------------------------------------------------\n",
      "#=================> epoch: 1 <=================#\n",
      "**Epoch_training_cost: tensor(0.0507)\n",
      "**Epoch_valid_cost: tensor(0.0112)\n",
      "#=================> epoch: 2 <=================#\n",
      "**Epoch_training_cost: tensor(0.0444)\n",
      "**Epoch_valid_cost: tensor(0.0104)\n",
      "#=================> epoch: 3 <=================#\n",
      "**Epoch_training_cost: tensor(0.0415)\n",
      "**Epoch_valid_cost: tensor(0.0098)\n",
      "#=================> epoch: 4 <=================#\n",
      "**Epoch_training_cost: tensor(0.0390)\n",
      "**Epoch_valid_cost: tensor(0.0095)\n",
      "#=================> epoch: 5 <=================#\n",
      "**Epoch_training_cost: tensor(0.0367)\n",
      "**Epoch_valid_cost: tensor(0.0087)\n",
      "#=================> epoch: 6 <=================#\n",
      "**Epoch_training_cost: tensor(0.0348)\n",
      "**Epoch_valid_cost: tensor(0.0083)\n",
      "#=================> epoch: 7 <=================#\n",
      "**Epoch_training_cost: tensor(0.0329)\n",
      "**Epoch_valid_cost: tensor(0.0077)\n",
      "#=================> epoch: 8 <=================#\n",
      "**Epoch_training_cost: tensor(0.0307)\n",
      "**Epoch_valid_cost: tensor(0.0074)\n",
      "#=================> epoch: 9 <=================#\n",
      "**Epoch_training_cost: tensor(0.0290)\n",
      "**Epoch_valid_cost: tensor(0.0068)\n",
      "#=================> epoch: 10 <=================#\n",
      "**Epoch_training_cost: tensor(0.0271)\n",
      "**Epoch_valid_cost: tensor(0.0064)\n",
      "#=================> epoch: 11 <=================#\n",
      "**Epoch_training_cost: tensor(0.0251)\n",
      "**Epoch_valid_cost: tensor(0.0059)\n",
      "#=================> epoch: 12 <=================#\n",
      "**Epoch_training_cost: tensor(0.0237)\n",
      "**Epoch_valid_cost: tensor(0.0056)\n",
      "#=================> epoch: 13 <=================#\n",
      "**Epoch_training_cost: tensor(0.0220)\n",
      "**Epoch_valid_cost: tensor(0.0053)\n",
      "#=================> epoch: 14 <=================#\n",
      "**Epoch_training_cost: tensor(0.0205)\n",
      "**Epoch_valid_cost: tensor(0.0047)\n",
      "#=================> epoch: 15 <=================#\n",
      "**Epoch_training_cost: tensor(0.0192)\n",
      "**Epoch_valid_cost: tensor(0.0047)\n",
      "#=================> epoch: 16 <=================#\n",
      "**Epoch_training_cost: tensor(0.0181)\n",
      "**Epoch_valid_cost: tensor(0.0043)\n",
      "#=================> epoch: 17 <=================#\n",
      "**Epoch_training_cost: tensor(0.0174)\n",
      "**Epoch_valid_cost: tensor(0.0039)\n",
      "#=================> epoch: 18 <=================#\n",
      "**Epoch_training_cost: tensor(0.0160)\n",
      "**Epoch_valid_cost: tensor(0.0038)\n",
      "#=================> epoch: 19 <=================#\n",
      "**Epoch_training_cost: tensor(0.0155)\n",
      "**Epoch_valid_cost: tensor(0.0037)\n",
      "#=================> epoch: 20 <=================#\n",
      "**Epoch_training_cost: tensor(0.0143)\n",
      "**Epoch_valid_cost: tensor(0.0032)\n",
      "#=================> epoch: 21 <=================#\n",
      "**Epoch_training_cost: tensor(0.0138)\n",
      "**Epoch_valid_cost: tensor(0.0032)\n",
      "#=================> epoch: 22 <=================#\n",
      "**Epoch_training_cost: tensor(0.0130)\n",
      "**Epoch_valid_cost: tensor(0.0032)\n",
      "#=================> epoch: 23 <=================#\n",
      "**Epoch_training_cost: tensor(0.0128)\n",
      "**Epoch_valid_cost: tensor(0.0030)\n",
      "#=================> epoch: 24 <=================#\n",
      "**Epoch_training_cost: tensor(0.0122)\n",
      "**Epoch_valid_cost: tensor(0.0030)\n",
      "#=================> epoch: 25 <=================#\n",
      "**Epoch_training_cost: tensor(0.0117)\n",
      "**Epoch_valid_cost: tensor(0.0029)\n",
      "#=================> epoch: 26 <=================#\n",
      "**Epoch_training_cost: tensor(0.0113)\n",
      "**Epoch_valid_cost: tensor(0.0028)\n",
      "#=================> epoch: 27 <=================#\n",
      "**Epoch_training_cost: tensor(0.0110)\n",
      "**Epoch_valid_cost: tensor(0.0027)\n",
      "#=================> epoch: 28 <=================#\n",
      "**Epoch_training_cost: tensor(0.0108)\n",
      "**Epoch_valid_cost: tensor(0.0027)\n",
      "#=================> epoch: 29 <=================#\n",
      "**Epoch_training_cost: tensor(0.0106)\n",
      "**Epoch_valid_cost: tensor(0.0025)\n",
      "#=================> epoch: 30 <=================#\n",
      "**Epoch_training_cost: tensor(0.0100)\n",
      "**Epoch_valid_cost: tensor(0.0025)\n",
      "#=================> epoch: 31 <=================#\n",
      "**Epoch_training_cost: tensor(0.0098)\n",
      "**Epoch_valid_cost: tensor(0.0025)\n",
      "#=================> epoch: 32 <=================#\n",
      "**Epoch_training_cost: tensor(0.0098)\n",
      "**Epoch_valid_cost: tensor(0.0023)\n",
      "#=================> epoch: 33 <=================#\n",
      "**Epoch_training_cost: tensor(0.0094)\n",
      "**Epoch_valid_cost: tensor(0.0024)\n",
      "#=================> epoch: 34 <=================#\n",
      "**Epoch_training_cost: tensor(0.0091)\n",
      "**Epoch_valid_cost: tensor(0.0022)\n",
      "#=================> epoch: 35 <=================#\n",
      "**Epoch_training_cost: tensor(0.0092)\n",
      "**Epoch_valid_cost: tensor(0.0023)\n",
      "#=================> epoch: 36 <=================#\n",
      "**Epoch_training_cost: tensor(0.0090)\n",
      "**Epoch_valid_cost: tensor(0.0022)\n",
      "#=================> epoch: 37 <=================#\n",
      "**Epoch_training_cost: tensor(0.0089)\n",
      "**Epoch_valid_cost: tensor(0.0022)\n",
      "#=================> epoch: 38 <=================#\n",
      "**Epoch_training_cost: tensor(0.0089)\n",
      "**Epoch_valid_cost: tensor(0.0021)\n",
      "#=================> epoch: 39 <=================#\n",
      "**Epoch_training_cost: tensor(0.0087)\n",
      "**Epoch_valid_cost: tensor(0.0021)\n",
      "#=================> epoch: 40 <=================#\n",
      "**Epoch_training_cost: tensor(0.0084)\n",
      "**Epoch_valid_cost: tensor(0.0021)\n",
      "#=================> epoch: 41 <=================#\n",
      "**Epoch_training_cost: tensor(0.0081)\n",
      "**Epoch_valid_cost: tensor(0.0021)\n",
      "#=================> epoch: 42 <=================#\n",
      "**Epoch_training_cost: tensor(0.0081)\n",
      "**Epoch_valid_cost: tensor(0.0020)\n",
      "#=================> epoch: 43 <=================#\n",
      "**Epoch_training_cost: tensor(0.0081)\n",
      "**Epoch_valid_cost: tensor(0.0020)\n",
      "#=================> epoch: 44 <=================#\n",
      "**Epoch_training_cost: tensor(0.0081)\n",
      "**Epoch_valid_cost: tensor(0.0020)\n",
      "#=================> epoch: 45 <=================#\n",
      "**Epoch_training_cost: tensor(0.0077)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 46 <=================#\n",
      "**Epoch_training_cost: tensor(0.0077)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 47 <=================#\n",
      "**Epoch_training_cost: tensor(0.0078)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 48 <=================#\n",
      "**Epoch_training_cost: tensor(0.0076)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 49 <=================#\n",
      "**Epoch_training_cost: tensor(0.0076)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 50 <=================#\n",
      "**Epoch_training_cost: tensor(0.0073)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 51 <=================#\n",
      "**Epoch_training_cost: tensor(0.0075)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 52 <=================#\n",
      "**Epoch_training_cost: tensor(0.0075)\n",
      "**Epoch_valid_cost: tensor(0.0019)\n",
      "#=================> epoch: 53 <=================#\n",
      "**Epoch_training_cost: tensor(0.0071)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 54 <=================#\n",
      "**Epoch_training_cost: tensor(0.0073)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 55 <=================#\n",
      "**Epoch_training_cost: tensor(0.0072)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 56 <=================#\n",
      "**Epoch_training_cost: tensor(0.0069)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 57 <=================#\n",
      "**Epoch_training_cost: tensor(0.0072)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 58 <=================#\n",
      "**Epoch_training_cost: tensor(0.0070)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 59 <=================#\n",
      "**Epoch_training_cost: tensor(0.0070)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 60 <=================#\n",
      "**Epoch_training_cost: tensor(0.0068)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 61 <=================#\n",
      "**Epoch_training_cost: tensor(0.0067)\n",
      "**Epoch_valid_cost: tensor(0.0018)\n",
      "#=================> epoch: 62 <=================#\n",
      "**Epoch_training_cost: tensor(0.0068)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 63 <=================#\n",
      "**Epoch_training_cost: tensor(0.0067)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 64 <=================#\n",
      "**Epoch_training_cost: tensor(0.0068)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 65 <=================#\n",
      "**Epoch_training_cost: tensor(0.0067)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 66 <=================#\n",
      "**Epoch_training_cost: tensor(0.0065)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 67 <=================#\n",
      "**Epoch_training_cost: tensor(0.0067)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 68 <=================#\n",
      "**Epoch_training_cost: tensor(0.0066)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 69 <=================#\n",
      "**Epoch_training_cost: tensor(0.0066)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 70 <=================#\n",
      "**Epoch_training_cost: tensor(0.0065)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 71 <=================#\n",
      "**Epoch_training_cost: tensor(0.0066)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 72 <=================#\n",
      "**Epoch_training_cost: tensor(0.0064)\n",
      "**Epoch_valid_cost: tensor(0.0017)\n",
      "#=================> epoch: 73 <=================#\n",
      "**Epoch_training_cost: tensor(0.0063)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 74 <=================#\n",
      "**Epoch_training_cost: tensor(0.0063)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 75 <=================#\n",
      "**Epoch_training_cost: tensor(0.0065)\n",
      "**Epoch_valid_cost: tensor(0.0016)\n",
      "#=================> epoch: 76 <=================#\n",
      "**Epoch_training_cost: tensor(0.0064)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 77 <=================#\n",
      "**Epoch_training_cost: tensor(0.0064)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 78 <=================#\n",
      "**Epoch_training_cost: tensor(0.0063)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 79 <=================#\n",
      "**Epoch_training_cost: tensor(0.0062)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 80 <=================#\n",
      "**Epoch_training_cost: tensor(0.0064)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 81 <=================#\n",
      "**Epoch_training_cost: tensor(0.0062)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 82 <=================#\n",
      "**Epoch_training_cost: tensor(0.0062)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 83 <=================#\n",
      "**Epoch_training_cost: tensor(0.0062)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 84 <=================#\n",
      "**Epoch_training_cost: tensor(0.0061)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 85 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 86 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 87 <=================#\n",
      "**Epoch_training_cost: tensor(0.0061)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 88 <=================#\n",
      "**Epoch_training_cost: tensor(0.0061)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 89 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 90 <=================#\n",
      "**Epoch_training_cost: tensor(0.0061)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 91 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 92 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 93 <=================#\n",
      "**Epoch_training_cost: tensor(0.0059)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 94 <=================#\n",
      "**Epoch_training_cost: tensor(0.0059)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 95 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 96 <=================#\n",
      "**Epoch_training_cost: tensor(0.0059)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 97 <=================#\n",
      "**Epoch_training_cost: tensor(0.0057)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 98 <=================#\n",
      "**Epoch_training_cost: tensor(0.0059)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 99 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 100 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 101 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 102 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 103 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 104 <=================#\n",
      "**Epoch_training_cost: tensor(0.0060)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 105 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 106 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 107 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 108 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 109 <=================#\n",
      "**Epoch_training_cost: tensor(0.0057)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 110 <=================#\n",
      "**Epoch_training_cost: tensor(0.0058)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 111 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0015)\n",
      "#=================> epoch: 112 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 113 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 114 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 115 <=================#\n",
      "**Epoch_training_cost: tensor(0.0057)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 116 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 117 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 118 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 119 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 120 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 121 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 122 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 123 <=================#\n",
      "**Epoch_training_cost: tensor(0.0056)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 124 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 125 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 126 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 127 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 128 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 129 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 130 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 131 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 132 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 133 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 134 <=================#\n",
      "**Epoch_training_cost: tensor(0.0055)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 135 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 136 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 137 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 138 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 139 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 140 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 141 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 142 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 143 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 144 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 145 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 146 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 147 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 148 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 149 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 150 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 151 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 152 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 153 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 154 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 155 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 156 <=================#\n",
      "**Epoch_training_cost: tensor(0.0054)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 157 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 158 <=================#\n",
      "**Epoch_training_cost: tensor(0.0053)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 159 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 160 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 161 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 162 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 163 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 164 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 165 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 166 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 167 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 168 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 169 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 170 <=================#\n",
      "**Epoch_training_cost: tensor(0.0051)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 171 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 172 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0014)\n",
      "#=================> epoch: 173 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 174 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 175 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 176 <=================#\n",
      "**Epoch_training_cost: tensor(0.0052)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 177 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 178 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 179 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 180 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 181 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 182 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 183 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 184 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 185 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 186 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 187 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0013)\n",
      "#=================> epoch: 188 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 189 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 190 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 191 <=================#\n",
      "**Epoch_training_cost: tensor(0.0050)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 192 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 193 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 194 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 195 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 196 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 197 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 198 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 199 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 200 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 201 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 202 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 203 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 204 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 205 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 206 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 207 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 208 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 209 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 210 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 211 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 212 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 213 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 214 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 215 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 216 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 217 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 218 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 219 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 220 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 221 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 222 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 223 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 224 <=================#\n",
      "**Epoch_training_cost: tensor(0.0049)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 225 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 226 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 227 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 228 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 229 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 230 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 231 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 232 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 233 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 234 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 235 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 236 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 237 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 238 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 239 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 240 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 241 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 242 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 243 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 244 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 245 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 246 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 247 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 248 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 249 <=================#\n",
      "**Epoch_training_cost: tensor(0.0048)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 250 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 251 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 252 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 253 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 254 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 255 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 256 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 257 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 258 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 259 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 260 <=================#\n",
      "**Epoch_training_cost: tensor(0.0047)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 261 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 262 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 263 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 264 <=================#\n",
      "**Epoch_training_cost: tensor(0.0046)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 265 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 266 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 267 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 268 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 269 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 270 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 271 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 272 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 273 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 274 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 275 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 276 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 277 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 278 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 279 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 280 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0012)\n",
      "#=================> epoch: 281 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 282 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 283 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 284 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 285 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 286 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 287 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 288 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 289 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 290 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 291 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 292 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 293 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 294 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 295 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 296 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 297 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 298 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 299 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 300 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 301 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 302 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 303 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 304 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 305 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 306 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 307 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 308 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 309 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 310 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 311 <=================#\n",
      "**Epoch_training_cost: tensor(0.0045)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 312 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 313 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 314 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 315 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 316 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 317 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 318 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 319 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 320 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 321 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 322 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 323 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 324 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 325 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 326 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 327 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 328 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 329 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 330 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 331 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 332 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 333 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 334 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 335 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 336 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 337 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 338 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 339 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 340 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 341 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 342 <=================#\n",
      "**Epoch_training_cost: tensor(0.0044)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 343 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 344 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 345 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 346 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 347 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 348 <=================#\n",
      "**Epoch_training_cost: tensor(0.0043)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 349 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 350 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 351 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 352 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 353 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 354 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 355 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 356 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 357 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 358 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 359 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 360 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 361 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 362 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 363 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 364 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 365 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 366 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 367 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 368 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 369 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 370 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 371 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 372 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 373 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 374 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 375 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 376 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 377 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 378 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 379 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 380 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 381 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 382 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 383 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 384 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 385 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 386 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 387 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 388 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 389 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 390 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 391 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 392 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 393 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 394 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 395 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 396 <=================#\n",
      "**Epoch_training_cost: tensor(0.0042)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 397 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 398 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 399 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 400 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 401 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 402 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 403 <=================#\n",
      "**Epoch_training_cost: tensor(0.0041)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 404 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 405 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 406 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 407 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 408 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 409 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 410 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 411 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 412 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 413 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 414 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 415 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 416 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 417 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 418 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 419 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 420 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 421 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 422 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 423 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 424 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 425 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 426 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 427 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 428 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 429 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 430 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 431 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 432 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 433 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 434 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 435 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 436 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 437 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 438 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 439 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 440 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 441 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 442 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 443 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 444 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 445 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 446 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 447 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 448 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 449 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 450 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 451 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 452 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 453 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 454 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 455 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 456 <=================#\n",
      "**Epoch_training_cost: tensor(0.0040)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 457 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 458 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 459 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 460 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 461 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 462 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 463 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0011)\n",
      "#=================> epoch: 464 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 465 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 466 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 467 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 468 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 469 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 470 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 471 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 472 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 473 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 474 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 475 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 476 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 477 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 478 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 479 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 480 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 481 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 482 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 483 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 484 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 485 <=================#\n",
      "**Epoch_training_cost: tensor(0.0039)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 486 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 487 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 488 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 489 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 490 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 491 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 492 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0010)\n",
      "#=================> epoch: 493 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 494 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 495 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 496 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 497 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 498 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 499 <=================#\n",
      "**Epoch_training_cost: tensor(0.0038)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 500 <=================#\n",
      "**Epoch_training_cost: tensor(0.0037)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 501 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n"
     ]
    }
   ],
   "source": [
    "training_1, validate_1 = [], []\n",
    "training_batch = samples_size * 0.8\n",
    "valid_batch = samples_size * 0.2\n",
    "mini_batch = 512\n",
    "total_iterations = int(training_batch/mini_batch)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"#================================ start_training ================================#\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "for epoch in range(0, 501):\n",
    "    print(\"#=================> epoch:\",epoch+1,\"<=================#\")\n",
    "    ## ======== Training ======== ##\n",
    "    batch_cost = 0\n",
    "    for iteration in range(0, total_iterations):\n",
    "        x, y = iteration*mini_batch , ((iteration+1)*mini_batch)\n",
    "        ##print(\"**iteration:\", iteration+1)\n",
    "        ##print(\"[ index:\",tr_x , \"~ index:\",tr_y, \"]\")\n",
    "        ##print(\"polar_codewords.shape\",polar_codewords[x:y].shape)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = mini_batch_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_training_cost:\", avg_batch_cost)\n",
    "    training_1.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)\n",
    "    batch_cost = 0\n",
    "    ## ======== Validation ======== ##\n",
    "    for valid_idx in range(201, 250):\n",
    "        x, y = valid_idx*mini_batch , ((valid_idx+1)*mini_batch)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = validation_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_valid_cost:\", avg_batch_cost)\n",
    "    validate_1.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save \n",
    "torch.save(decoder, 'FT_4-layerNN_V9__3-dB.pt') \n",
    "# model save weight\n",
    "torch.save(decoder.state_dict(), 'FT_4-layerNN_V9__3-dB.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_1: [tensor(0.0507), tensor(0.0444), tensor(0.0415), tensor(0.0390), tensor(0.0367), tensor(0.0348), tensor(0.0329), tensor(0.0307), tensor(0.0290), tensor(0.0271), tensor(0.0251), tensor(0.0237), tensor(0.0220), tensor(0.0205), tensor(0.0192), tensor(0.0181), tensor(0.0174), tensor(0.0160), tensor(0.0155), tensor(0.0143), tensor(0.0138), tensor(0.0130), tensor(0.0128), tensor(0.0122), tensor(0.0117), tensor(0.0113), tensor(0.0110), tensor(0.0108), tensor(0.0106), tensor(0.0100), tensor(0.0098), tensor(0.0098), tensor(0.0094), tensor(0.0091), tensor(0.0092), tensor(0.0090), tensor(0.0089), tensor(0.0089), tensor(0.0087), tensor(0.0084), tensor(0.0081), tensor(0.0081), tensor(0.0081), tensor(0.0081), tensor(0.0077), tensor(0.0077), tensor(0.0078), tensor(0.0076), tensor(0.0076), tensor(0.0073), tensor(0.0075), tensor(0.0075), tensor(0.0071), tensor(0.0073), tensor(0.0072), tensor(0.0069), tensor(0.0072), tensor(0.0070), tensor(0.0070), tensor(0.0068), tensor(0.0067), tensor(0.0068), tensor(0.0067), tensor(0.0068), tensor(0.0067), tensor(0.0065), tensor(0.0067), tensor(0.0066), tensor(0.0066), tensor(0.0065), tensor(0.0066), tensor(0.0064), tensor(0.0063), tensor(0.0063), tensor(0.0065), tensor(0.0064), tensor(0.0064), tensor(0.0063), tensor(0.0062), tensor(0.0064), tensor(0.0062), tensor(0.0062), tensor(0.0062), tensor(0.0061), tensor(0.0060), tensor(0.0060), tensor(0.0061), tensor(0.0061), tensor(0.0060), tensor(0.0061), tensor(0.0060), tensor(0.0058), tensor(0.0059), tensor(0.0059), tensor(0.0058), tensor(0.0059), tensor(0.0057), tensor(0.0059), tensor(0.0056), tensor(0.0056), tensor(0.0058), tensor(0.0056), tensor(0.0058), tensor(0.0060), tensor(0.0056), tensor(0.0058), tensor(0.0058), tensor(0.0058), tensor(0.0057), tensor(0.0058), tensor(0.0055), tensor(0.0056), tensor(0.0056), tensor(0.0054), tensor(0.0057), tensor(0.0056), tensor(0.0056), tensor(0.0055), tensor(0.0056), tensor(0.0055), tensor(0.0055), tensor(0.0056), tensor(0.0056), tensor(0.0053), tensor(0.0054), tensor(0.0054), tensor(0.0053), tensor(0.0052), tensor(0.0055), tensor(0.0055), tensor(0.0054), tensor(0.0053), tensor(0.0055), tensor(0.0055), tensor(0.0053), tensor(0.0053), tensor(0.0053), tensor(0.0054), tensor(0.0053), tensor(0.0051), tensor(0.0053), tensor(0.0052), tensor(0.0053), tensor(0.0052), tensor(0.0052), tensor(0.0051), tensor(0.0053), tensor(0.0052), tensor(0.0051), tensor(0.0051), tensor(0.0051), tensor(0.0050), tensor(0.0053), tensor(0.0052), tensor(0.0051), tensor(0.0054), tensor(0.0051), tensor(0.0053), tensor(0.0051), tensor(0.0051), tensor(0.0050), tensor(0.0051), tensor(0.0050), tensor(0.0051), tensor(0.0052), tensor(0.0049), tensor(0.0050), tensor(0.0050), tensor(0.0050), tensor(0.0051), tensor(0.0050), tensor(0.0052), tensor(0.0050), tensor(0.0050), tensor(0.0050), tensor(0.0052), tensor(0.0049), tensor(0.0050), tensor(0.0050), tensor(0.0049), tensor(0.0046), tensor(0.0047), tensor(0.0050), tensor(0.0050), tensor(0.0048), tensor(0.0050), tensor(0.0048), tensor(0.0047), tensor(0.0050), tensor(0.0049), tensor(0.0050), tensor(0.0047), tensor(0.0047), tensor(0.0049), tensor(0.0046), tensor(0.0048), tensor(0.0048), tensor(0.0049), tensor(0.0049), tensor(0.0047), tensor(0.0047), tensor(0.0046), tensor(0.0047), tensor(0.0046), tensor(0.0048), tensor(0.0047), tensor(0.0048), tensor(0.0048), tensor(0.0046), tensor(0.0047), tensor(0.0047), tensor(0.0047), tensor(0.0047), tensor(0.0047), tensor(0.0048), tensor(0.0047), tensor(0.0045), tensor(0.0044), tensor(0.0045), tensor(0.0047), tensor(0.0046), tensor(0.0046), tensor(0.0046), tensor(0.0049), tensor(0.0047), tensor(0.0046), tensor(0.0046), tensor(0.0046), tensor(0.0047), tensor(0.0047), tensor(0.0047), tensor(0.0044), tensor(0.0047), tensor(0.0045), tensor(0.0045), tensor(0.0047), tensor(0.0045), tensor(0.0046), tensor(0.0048), tensor(0.0046), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0044), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0046), tensor(0.0048), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0046), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0047), tensor(0.0044), tensor(0.0047), tensor(0.0044), tensor(0.0044), tensor(0.0044), tensor(0.0046), tensor(0.0044), tensor(0.0044), tensor(0.0045), tensor(0.0044), tensor(0.0042), tensor(0.0044), tensor(0.0045), tensor(0.0043), tensor(0.0045), tensor(0.0045), tensor(0.0045), tensor(0.0043), tensor(0.0044), tensor(0.0044), tensor(0.0044), tensor(0.0044), tensor(0.0044), tensor(0.0045), tensor(0.0043), tensor(0.0043), tensor(0.0044), tensor(0.0042), tensor(0.0044), tensor(0.0045), tensor(0.0045), tensor(0.0041), tensor(0.0043), tensor(0.0043), tensor(0.0044), tensor(0.0044), tensor(0.0043), tensor(0.0043), tensor(0.0043), tensor(0.0043), tensor(0.0043), tensor(0.0042), tensor(0.0045), tensor(0.0042), tensor(0.0042), tensor(0.0044), tensor(0.0042), tensor(0.0043), tensor(0.0042), tensor(0.0043), tensor(0.0043), tensor(0.0044), tensor(0.0045), tensor(0.0042), tensor(0.0043), tensor(0.0043), tensor(0.0044), tensor(0.0044), tensor(0.0044), tensor(0.0043), tensor(0.0043), tensor(0.0042), tensor(0.0043), tensor(0.0043), tensor(0.0042), tensor(0.0041), tensor(0.0042), tensor(0.0042), tensor(0.0043), tensor(0.0040), tensor(0.0042), tensor(0.0041), tensor(0.0040), tensor(0.0041), tensor(0.0042), tensor(0.0043), tensor(0.0041), tensor(0.0042), tensor(0.0041), tensor(0.0041), tensor(0.0040), tensor(0.0040), tensor(0.0041), tensor(0.0044), tensor(0.0042), tensor(0.0041), tensor(0.0039), tensor(0.0042), tensor(0.0043), tensor(0.0043), tensor(0.0041), tensor(0.0041), tensor(0.0042), tensor(0.0041), tensor(0.0041), tensor(0.0042), tensor(0.0041), tensor(0.0042), tensor(0.0041), tensor(0.0041), tensor(0.0041), tensor(0.0042), tensor(0.0041), tensor(0.0040), tensor(0.0041), tensor(0.0041), tensor(0.0041), tensor(0.0040), tensor(0.0039), tensor(0.0039), tensor(0.0041), tensor(0.0039), tensor(0.0040), tensor(0.0040), tensor(0.0041), tensor(0.0040), tensor(0.0040), tensor(0.0038), tensor(0.0040), tensor(0.0040), tensor(0.0040), tensor(0.0039), tensor(0.0041), tensor(0.0041), tensor(0.0041), tensor(0.0038), tensor(0.0040), tensor(0.0040), tensor(0.0039), tensor(0.0040), tensor(0.0041), tensor(0.0039), tensor(0.0040), tensor(0.0039), tensor(0.0038), tensor(0.0037), tensor(0.0040), tensor(0.0042), tensor(0.0041), tensor(0.0040), tensor(0.0039), tensor(0.0040), tensor(0.0040), tensor(0.0040), tensor(0.0041), tensor(0.0038), tensor(0.0037), tensor(0.0039), tensor(0.0038), tensor(0.0039), tensor(0.0039), tensor(0.0040), tensor(0.0038), tensor(0.0040), tensor(0.0040), tensor(0.0038), tensor(0.0040), tensor(0.0040), tensor(0.0039), tensor(0.0039), tensor(0.0039), tensor(0.0040), tensor(0.0040), tensor(0.0040), tensor(0.0039), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0039), tensor(0.0040), tensor(0.0038), tensor(0.0040), tensor(0.0038), tensor(0.0039), tensor(0.0039), tensor(0.0038), tensor(0.0038), tensor(0.0039), tensor(0.0038), tensor(0.0040), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0040), tensor(0.0038), tensor(0.0037), tensor(0.0039), tensor(0.0038), tensor(0.0039), tensor(0.0039), tensor(0.0039), tensor(0.0039), tensor(0.0038), tensor(0.0037), tensor(0.0038), tensor(0.0040), tensor(0.0038), tensor(0.0040), tensor(0.0039), tensor(0.0039), tensor(0.0038), tensor(0.0037), tensor(0.0039), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0039), tensor(0.0039), tensor(0.0038), tensor(0.0036), tensor(0.0038), tensor(0.0039), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0037), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0037), tensor(0.0038), tensor(0.0038), tensor(0.0039), tensor(0.0038), tensor(0.0037), tensor(0.0036), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0038), tensor(0.0037), tensor(0.0036), tensor(0.0036), tensor(0.0037), tensor(0.0038), tensor(0.0037), tensor(0.0036)]\n"
     ]
    }
   ],
   "source": [
    "print(\"training_1:\",training_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_1: [tensor(0.0112), tensor(0.0104), tensor(0.0098), tensor(0.0095), tensor(0.0087), tensor(0.0083), tensor(0.0077), tensor(0.0074), tensor(0.0068), tensor(0.0064), tensor(0.0059), tensor(0.0056), tensor(0.0053), tensor(0.0047), tensor(0.0047), tensor(0.0043), tensor(0.0039), tensor(0.0038), tensor(0.0037), tensor(0.0032), tensor(0.0032), tensor(0.0032), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0027), tensor(0.0025), tensor(0.0025), tensor(0.0025), tensor(0.0023), tensor(0.0024), tensor(0.0022), tensor(0.0023), tensor(0.0022), tensor(0.0022), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0021), tensor(0.0020), tensor(0.0020), tensor(0.0020), tensor(0.0019), tensor(0.0018), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0019), tensor(0.0018), tensor(0.0019), tensor(0.0018), tensor(0.0018), tensor(0.0018), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0017), tensor(0.0016), tensor(0.0018), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0015), tensor(0.0017), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0016), tensor(0.0017), tensor(0.0016), tensor(0.0015), tensor(0.0016), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0015), tensor(0.0015), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0014), tensor(0.0015), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0013), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0014), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0014), tensor(0.0013), tensor(0.0014), tensor(0.0012), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0013), tensor(0.0014), tensor(0.0011), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0014), tensor(0.0012), tensor(0.0013), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0013), tensor(0.0013), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0012), tensor(0.0010), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0012), tensor(0.0012), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0012), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0011), tensor(0.0010), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0008), tensor(0.0009), tensor(0.0009), tensor(0.0010), tensor(0.0009), tensor(0.0008), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009)]\n"
     ]
    }
   ],
   "source": [
    "print(\"validate_1:\",validate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "#decoder.load_state_dict(torch.load('AWGN_4-layerNN_V7__0-dB.pt'))\n",
    "#decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your optimizer\n",
    "optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-5)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "def mini_batch_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    batch_loss.backward()                   # 反向传播求梯度\n",
    "    optimizer.step()                        # 更新所有参数\n",
    "    return batch_loss.detach()\n",
    "\n",
    "def validation_loss(x, target):\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()                   # 上一個 batch 的梯度清為零\n",
    "    x_data = torch.tensor(x)\n",
    "    predi_out = decoder(x_data.float())     # 前向传播求出预测的值\n",
    "    batch_loss = loss_function(predi_out, torch.tensor(target).float()) # 求 loss\n",
    "    return batch_loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "#================================ start_training ================================#\n",
      "----------------------------------------------------------------------------------\n",
      "#=================> epoch: 1 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 2 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 3 <=================#\n",
      "**Epoch_training_cost: tensor(0.0036)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 4 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 5 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 6 <=================#\n",
      "**Epoch_training_cost: tensor(0.0035)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 7 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 8 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 9 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 10 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 11 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 12 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 13 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 14 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 15 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 16 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 17 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 18 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 19 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 20 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 21 <=================#\n",
      "**Epoch_training_cost: tensor(0.0034)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 22 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 23 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 24 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 25 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 26 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 27 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 28 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 29 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 30 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 31 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 32 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 33 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 34 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 35 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 36 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 37 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 38 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 39 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 40 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 41 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 42 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 43 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 44 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 45 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 46 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 47 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 48 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 49 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 50 <=================#\n",
      "**Epoch_training_cost: tensor(0.0033)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 51 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 52 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 53 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 54 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 55 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 56 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 57 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 58 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 59 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 60 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 61 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 62 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 63 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 64 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 65 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 66 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 67 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 68 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 69 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 70 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 71 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 72 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 73 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 74 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 75 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 76 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 77 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 78 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 79 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 80 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 81 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 82 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 83 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 84 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 85 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 86 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 87 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 88 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 89 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 90 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 91 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 92 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 93 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 94 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 95 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 96 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 97 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 98 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 99 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 100 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 101 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 102 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 103 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 104 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 105 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 106 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0009)\n",
      "#=================> epoch: 107 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 108 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 109 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 110 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 111 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 112 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 113 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 114 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 115 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 116 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 117 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 118 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 119 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 120 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 121 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 122 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 123 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 124 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 125 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 126 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 127 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 128 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 129 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 130 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 131 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 132 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 133 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 134 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 135 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 136 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 137 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 138 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 139 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 140 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 141 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 142 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 143 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 144 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 145 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 146 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 147 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 148 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 149 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 150 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 151 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 152 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 153 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 154 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 155 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 156 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 157 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 158 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 159 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 160 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 161 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 162 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 163 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 164 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 165 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 166 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 167 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 168 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 169 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 170 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 171 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 172 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 173 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 174 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 175 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 176 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 177 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 178 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 179 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 180 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 181 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 182 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 183 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 184 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 185 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 186 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 187 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 188 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 189 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 190 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 191 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 192 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 193 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 194 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 195 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 196 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 197 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 198 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 199 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 200 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 201 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 202 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 203 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 204 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 205 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 206 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 207 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 208 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 209 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 210 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 211 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 212 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 213 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 214 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 215 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 216 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 217 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 218 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 219 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 220 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 221 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 222 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 223 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 224 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 225 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 226 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 227 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 228 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 229 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 230 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 231 <=================#\n",
      "**Epoch_training_cost: tensor(0.0032)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 232 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 233 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 234 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 235 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 236 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 237 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 238 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 239 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 240 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 241 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 242 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 243 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 244 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 245 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 246 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 247 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 248 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 249 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 250 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 251 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 252 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 253 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 254 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 255 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 256 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 257 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 258 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 259 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 260 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 261 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 262 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 263 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 264 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 265 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 266 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 267 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 268 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 269 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 270 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 271 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 272 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 273 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 274 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 275 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 276 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 277 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 278 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 279 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 280 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 281 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 282 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 283 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 284 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 285 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 286 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 287 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 288 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 289 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 290 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 291 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 292 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 293 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 294 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 295 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 296 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 297 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 298 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 299 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 300 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 301 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 302 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 303 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 304 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 305 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 306 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 307 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 308 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 309 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 310 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 311 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 312 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 313 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 314 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 315 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 316 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 317 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 318 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 319 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 320 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 321 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 322 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 323 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 324 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 325 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 326 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 327 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 328 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 329 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 330 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 331 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 332 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 333 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 334 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 335 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 336 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 337 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 338 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 339 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 340 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 341 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 342 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 343 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 344 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 345 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 346 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 347 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 348 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 349 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 350 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 351 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 352 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 353 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 354 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 355 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 356 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 357 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 358 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 359 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 360 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 361 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 362 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 363 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 364 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 365 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 366 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 367 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 368 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 369 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 370 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 371 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 372 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 373 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 374 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 375 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 376 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 377 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 378 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 379 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 380 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 381 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 382 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 383 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 384 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 385 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 386 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 387 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 388 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 389 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 390 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 391 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 392 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 393 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 394 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 395 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 396 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 397 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 398 <=================#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 399 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 400 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 401 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 402 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 403 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 404 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 405 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 406 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 407 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 408 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 409 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 410 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 411 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 412 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 413 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 414 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 415 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 416 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 417 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 418 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 419 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 420 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 421 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 422 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 423 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 424 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 425 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 426 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 427 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 428 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 429 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 430 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 431 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 432 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 433 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 434 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 435 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 436 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 437 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 438 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 439 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 440 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 441 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 442 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 443 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 444 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 445 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 446 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 447 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 448 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 449 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 450 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 451 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 452 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 453 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 454 <=================#\n",
      "**Epoch_training_cost: tensor(0.0031)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 455 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 456 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 457 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 458 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 459 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 460 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 461 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 462 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 463 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 464 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 465 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 466 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 467 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 468 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 469 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 470 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 471 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 472 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 473 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 474 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 475 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 476 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 477 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 478 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 479 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 480 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 481 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 482 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 483 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 484 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 485 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 486 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 487 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 488 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 489 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 490 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 491 <=================#\n",
      "**Epoch_training_cost: tensor(0.0030)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n",
      "#=================> epoch: 492 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0008)\n",
      "#=================> epoch: 493 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 494 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 495 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 496 <=================#\n",
      "**Epoch_training_cost: tensor(0.0026)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 497 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 498 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 499 <=================#\n",
      "**Epoch_training_cost: tensor(0.0027)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 500 <=================#\n",
      "**Epoch_training_cost: tensor(0.0028)\n",
      "**Epoch_valid_cost: tensor(0.0007)\n",
      "#=================> epoch: 501 <=================#\n",
      "**Epoch_training_cost: tensor(0.0029)\n",
      "**Epoch_valid_cost: tensor(0.0006)\n"
     ]
    }
   ],
   "source": [
    "training_2, validate_2 = [], []\n",
    "training_batch = samples_size * 0.8\n",
    "valid_batch = samples_size * 0.2\n",
    "mini_batch = 512\n",
    "total_iterations = int(training_batch/mini_batch)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"#================================ start_training ================================#\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "for epoch in range(0, 501):\n",
    "    print(\"#=================> epoch:\",epoch+1,\"<=================#\")\n",
    "    ## ======== Training ======== ##\n",
    "    batch_cost = 0\n",
    "    for iteration in range(0, total_iterations):\n",
    "        x, y = iteration*mini_batch , ((iteration+1)*mini_batch)\n",
    "        ##print(\"**iteration:\", iteration+1)\n",
    "        ##print(\"[ index:\",tr_x , \"~ index:\",tr_y, \"]\")\n",
    "        ##print(\"polar_codewords.shape\",polar_codewords[x:y].shape)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = mini_batch_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_training_cost:\", avg_batch_cost)\n",
    "    training_2.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)\n",
    "    batch_cost = 0\n",
    "    ## ======== Validation ======== ##\n",
    "    for valid_idx in range(201, 250):\n",
    "        x, y = valid_idx*mini_batch , ((valid_idx+1)*mini_batch)\n",
    "        qpsk_codewords = QPSK_modulator(polar_codewords[x:y])\n",
    "        noise_codewords = FineTuning_addNoise(x=qpsk_codewords, awgn_power=noise_power)\n",
    "        batch_loss = validation_loss(x=noise_codewords, target=info_codewords[x:y])\n",
    "        batch_cost = batch_cost + batch_loss\n",
    "    avg_batch_cost = batch_cost/total_iterations\n",
    "    print(\"**Epoch_valid_cost:\", avg_batch_cost)\n",
    "    validate_2.append(avg_batch_cost)\n",
    "    gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save \n",
    "torch.save(decoder, 'FT_4-layerNN_V9__3-dB.pt') \n",
    "# model save weight\n",
    "torch.save(decoder.state_dict(), 'FT_4-layerNN_V9__3-dB.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_2: [tensor(0.0036), tensor(0.0036), tensor(0.0036), tensor(0.0033), tensor(0.0034), tensor(0.0035), tensor(0.0034), tensor(0.0034), tensor(0.0032), tensor(0.0034), tensor(0.0033), tensor(0.0034), tensor(0.0033), tensor(0.0034), tensor(0.0034), tensor(0.0033), tensor(0.0032), tensor(0.0034), tensor(0.0033), tensor(0.0032), tensor(0.0034), tensor(0.0033), tensor(0.0032), tensor(0.0033), tensor(0.0031), tensor(0.0033), tensor(0.0031), tensor(0.0033), tensor(0.0032), tensor(0.0032), tensor(0.0032), tensor(0.0031), tensor(0.0032), tensor(0.0030), tensor(0.0031), tensor(0.0032), tensor(0.0032), tensor(0.0033), tensor(0.0032), tensor(0.0030), tensor(0.0031), tensor(0.0032), tensor(0.0033), tensor(0.0031), tensor(0.0033), tensor(0.0030), tensor(0.0032), tensor(0.0030), tensor(0.0030), tensor(0.0033), tensor(0.0031), tensor(0.0031), tensor(0.0031), tensor(0.0031), tensor(0.0030), tensor(0.0032), tensor(0.0031), tensor(0.0032), tensor(0.0032), tensor(0.0031), tensor(0.0032), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0031), tensor(0.0032), tensor(0.0032), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0032), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0030), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0032), tensor(0.0031), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0032), tensor(0.0031), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0031), tensor(0.0031), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0031), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0031), tensor(0.0028), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0031), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0030), tensor(0.0029), tensor(0.0031), tensor(0.0029), tensor(0.0028), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0031), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0032), tensor(0.0031), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0027), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0029), tensor(0.0028), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0027), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0027), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0030), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0031), tensor(0.0030), tensor(0.0028), tensor(0.0030), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0027), tensor(0.0029), tensor(0.0029), tensor(0.0030), tensor(0.0029), tensor(0.0029), tensor(0.0031), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0029), tensor(0.0027), tensor(0.0027), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0030), tensor(0.0028), tensor(0.0027), tensor(0.0031), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0028), tensor(0.0030), tensor(0.0028), tensor(0.0028), tensor(0.0027), tensor(0.0027), tensor(0.0028), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0029), tensor(0.0028), tensor(0.0028), tensor(0.0030), tensor(0.0027), tensor(0.0027), tensor(0.0027), tensor(0.0028), tensor(0.0030), tensor(0.0028), tensor(0.0029), tensor(0.0027), tensor(0.0028), tensor(0.0026), tensor(0.0029), tensor(0.0028), tensor(0.0027), tensor(0.0028), tensor(0.0029)]\n"
     ]
    }
   ],
   "source": [
    "print(\"training_2:\",training_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_2: [tensor(0.0008), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0008), tensor(0.0008), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0009), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0009), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0009), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0009), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0006), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0006), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0006), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0008), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0008), tensor(0.0006), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006), tensor(0.0008), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0007), tensor(0.0006)]\n"
     ]
    }
   ],
   "source": [
    "print(\"validate_2:\",validate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# No Smoothing :\n",
    "legend = []\n",
    "total_training_loss = training_1 + training_2 + training_3\n",
    "total_valid_loss = validate_1 + validate_2 + validate_3\n",
    "plt.plot(torch.Tensor(total_training_loss).detach().numpy(), linewidth = '2.5', linestyle='--')\n",
    "legend.append(\"Training_loss\")\n",
    "plt.plot(torch.Tensor(total_valid_loss).detach().numpy()*4, linewidth = '2.5', linestyle='--')\n",
    "legend.append(\"Validation_loss\")\n",
    "plt.title('Model loss', fontsize=17)\n",
    "plt.ylabel('Loss', fontsize=15)\n",
    "plt.xlabel('Epoch', fontsize=15)\n",
    "## plt.legend(['Fine-Tuning Training-Loss'], fontsize=15)\n",
    "plt.legend(legend, loc = 0, fontsize=15)\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.rcParams['figure.figsize'] = (10, 7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
